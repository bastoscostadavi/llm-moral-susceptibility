#!/usr/bin/env python3
"""Aggregate failure counts from raw persona MFQ runs."""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Iterable

import pandas as pd


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=Path("data"),
        help="Directory containing raw rerun CSVs (default: data).",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("articles") / "failures_by_model.tex",
        help="Destination TeX table (default: articles/failures_by_model.tex).",
    )
    parser.add_argument(
        "--include-self",
        action="store_true",
        help="Include *_self.csv files in the aggregation (default: skip).",
    )
    return parser.parse_args()


def iter_csv_files(data_dir: Path, include_self: bool) -> Iterable[Path]:
    if not data_dir.exists():
        raise FileNotFoundError(f"Data directory not found: {data_dir}")
    for path in sorted(data_dir.glob("*.csv")):
        if not include_self and path.name.endswith("_self.csv"):
            continue
        if path.is_file():
            yield path


def summarize_file(csv_path: Path) -> tuple[str, int, int]:
    df = pd.read_csv(csv_path)
    if "failures" not in df.columns:
        return csv_path.stem, 0, 0

    failures = pd.to_numeric(df["failures"], errors="coerce").fillna(0)
    failed_rows = int((failures > 0).sum())
    total_failures = int(failures.clip(lower=0).sum())
    return csv_path.stem, failed_rows, total_failures


def main() -> None:
    args = parse_args()

    rows = []
    for csv_path in iter_csv_files(args.data_dir, args.include_self):
        model, failed_rows, total_failures = summarize_file(csv_path)
        rows.append(
            {
                "model": model,
                "failed_rows": failed_rows,
                "total_failures": total_failures,
            }
        )

    if not rows:
        raise SystemExit("No CSV files processed; check --data-dir or --include-self settings.")

    summary = (
        pd.DataFrame(rows)
        .sort_values("model")
        .reset_index(drop=True)
    )

    # Keep only datasets with non-zero totals, matching paper text
    nonzero = summary[summary["total_failures"] > 0].copy()

    # Render LaTeX table
    lines: list[str] = []
    lines.append("% Auto-generated by analysis/summarize_failures.py")
    lines.append("\\begin{table}[t]")
    lines.append("  \\centering")
    lines.append(
        "  \\caption{Parsing failures per dataset (raw reruns under \\texttt{data/}).}"
    )
    lines.append("  \\label{tab:failures_by_model}")
    lines.append("  \\begin{tabular}{lrr}")
    lines.append("    \\toprule")
    lines.append("    Dataset & Failed rows & Total failures \\\\")
    lines.append("    \\midrule")

    def _escape(text: str) -> str:
        return str(text).replace("_", r"\\_")

    for _, row in nonzero.iterrows():
        dataset = _escape(row["model"])  # stem of CSV filename
        failed_rows = int(row["failed_rows"]) if pd.notna(row["failed_rows"]) else 0
        total = int(row["total_failures"]) if pd.notna(row["total_failures"]) else 0
        lines.append(f"    {dataset} & {failed_rows} & {total} \\\\")

    lines.append("    \\bottomrule")
    lines.append("  \\end{tabular}")
    lines.append("\\end{table}")

    args.output.parent.mkdir(parents=True, exist_ok=True)
    args.output.write_text("\n".join(lines) + "\n", encoding="utf-8")


if __name__ == "__main__":
    main()
